{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanford CME 241 (Winter 2021) - Assignment 3\n",
    "## Frog on Lilypad (code part)\n",
    "\n",
    "### Chih-Hsuan 'Carolyn' Kao (chkao831@stanford.edu)\n",
    "### Feb 28th, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chih-hsuankao/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/scipy/__init__.py:137: UserWarning: NumPy 1.16.5 or above is required for this version of SciPy (detected version 1.16.2)\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/chih-hsuankao/Desktop/CME241/RL-book/')\n",
    "\n",
    "from rl.distribution import Categorical, Constant\n",
    "from rl.dynamic_programming import (\n",
    "    evaluate_mrp_result,\n",
    "    policy_iteration_result,\n",
    "    value_iteration_result\n",
    ")\n",
    "from rl.markov_decision_process import (\n",
    "    FiniteMarkovDecisionProcess,\n",
    "    FinitePolicy,\n",
    "    StateActionMapping,\n",
    ")\n",
    "from rl.markov_process import (\n",
    "    Transition,\n",
    "    RewardTransition,\n",
    "    FiniteMarkovProcess,\n",
    "    Optional,\n",
    "    FiniteMarkovRewardProcess,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Mapping, Dict, Tuple, List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider an array of $n + 1$ lilypads on a pond, numbered $0$ to $n$. A frog sits on a lilypad other\n",
    "than the lilypads numbered $0$ or $n$. When on lilypad $i$ $(1 \\leq i \\leq n − 1)$, the frog can croak one of two sounds A or B. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it croaks A when on lilypad $i$ $(1 \\leq i \\leq n − 1)$, it is thrown to lilypad $i−1$ with probability $\\frac{i}{n}$ and is thrown to lilypad $i + 1$ with probability $\\frac{n-i}{n}$. If it croaks B when on lilypad $i$ $(1 \\leq i \\leq n − 1)$, it is thrown to one of the lilypads $0,...,i−1,i+1,...n$ with uniform probability $\\frac{1}{n}$. A snake, perched on lilypad $0$, will eat the frog if the frog lands on lilypad $0$. The frog can escape the pond (and hence, escape the snake!) if it lands on lilypad $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What should the frog croak when on each of the lilypads $1, 2, . . . , n − 1$, in order to maximize the probability of escaping the pond (i.e., reaching lilypad $n$ before reaching lilypad $0$)? Although there are more than one ways of solving this problem, we’d like to solve it by modeling it as an MDP and identifying the Optimal Policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to model this MDP as an instance of the FiniteMarkovDecisionProcess class. We have learnt that there exists an optimal deterministic policy, and there are $2^{n−1}$ possible deterministic policies for this problem. Write code to create each of these $2^{n−1}$ deterministic policies (as instances of FinitePolicy class), create a policy-implied Finite MRP for each of these deterministic policies (using the apply finite policy method of FiniteMarkovDecisionProcess class), and evaluate the Value Function for each of those implied Finite MRPs. This should gives you the Optimal Value Function and the Optimal Deterministic Policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class FrogState:\n",
    "    position: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FrogJumpMap = StateActionMapping[FrogState, int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrogMDP(FiniteMarkovDecisionProcess[FrogState, str]):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        num_pad: int = 10,\n",
    "    ):\n",
    "        self.num_pad = num_pad\n",
    "        \n",
    "        super().__init__(self.get_action_transition_reward_map())\n",
    "\n",
    "    def get_action_transition_reward_map(self) -> StateActionMapping[FrogState, str]:\n",
    "        \n",
    "        d: Dict[FrogState, Dict[str, Categorical[Tuple[FrogState, float]]]] = {}\n",
    "\n",
    "        # ref: https://github.com/coverdrive/MDP-DP-RL/blob/master/src/examples/exam_problems/frog_lilypad.py\n",
    "        for i in range(1, self.num_pad):\n",
    "            \n",
    "            d1: Dict[str, Categorical[Tuple[FrogState, float]]] = {}\n",
    "                \n",
    "            # Croak A\n",
    "            d1[\"A\"] = Categorical({(FrogState(i - 1), 0.): \n",
    "                                       i / self.num_pad,\n",
    "                                   (FrogState(i + 1), 1. if i == self.num_pad-1 else 0.): \n",
    "                                       (self.num_pad - i) /self.num_pad})\n",
    "            # Croak B\n",
    "            d1[\"B\"] = Categorical({(FrogState(j), 1. if j == self.num_pad else 0.):\n",
    "                                       1/self.num_pad for j in range(self.num_pad + 1) if j != i})\n",
    "               \n",
    "            d[FrogState(i)] = d1\n",
    "        \n",
    "        d[FrogState(self.num_pad)] = None\n",
    "        d[FrogState(0)] = None\n",
    "            \n",
    "        return d\n",
    "    \n",
    "    def rewardf(\n",
    "        self,\n",
    "        current_pad: int,\n",
    "        num_pad: int\n",
    "    ):\n",
    "        if current_pad == num_pad:\n",
    "            return 1.\n",
    "        \n",
    "        elif current_pad == 0:\n",
    "            return -1.\n",
    "        \n",
    "        else:\n",
    "            return 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDP Transition Map\n",
      "------------------\n",
      "From State FrogState(position=1):\n",
      "  With Action A:\n",
      "    To [State FrogState(position=0) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=2) and Reward 0.000] with Probability 0.900\n",
      "  With Action B:\n",
      "    To [State FrogState(position=0) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=2) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=3) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=4) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=5) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=6) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=7) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=8) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=9) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=10) and Reward 1.000] with Probability 0.100\n",
      "From State FrogState(position=2):\n",
      "  With Action A:\n",
      "    To [State FrogState(position=1) and Reward 0.000] with Probability 0.200\n",
      "    To [State FrogState(position=3) and Reward 0.000] with Probability 0.800\n",
      "  With Action B:\n",
      "    To [State FrogState(position=0) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=1) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=3) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=4) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=5) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=6) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=7) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=8) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=9) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=10) and Reward 1.000] with Probability 0.100\n",
      "From State FrogState(position=3):\n",
      "  With Action A:\n",
      "    To [State FrogState(position=2) and Reward 0.000] with Probability 0.300\n",
      "    To [State FrogState(position=4) and Reward 0.000] with Probability 0.700\n",
      "  With Action B:\n",
      "    To [State FrogState(position=0) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=1) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=2) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=4) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=5) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=6) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=7) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=8) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=9) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=10) and Reward 1.000] with Probability 0.100\n",
      "From State FrogState(position=4):\n",
      "  With Action A:\n",
      "    To [State FrogState(position=3) and Reward 0.000] with Probability 0.400\n",
      "    To [State FrogState(position=5) and Reward 0.000] with Probability 0.600\n",
      "  With Action B:\n",
      "    To [State FrogState(position=0) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=1) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=2) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=3) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=5) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=6) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=7) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=8) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=9) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=10) and Reward 1.000] with Probability 0.100\n",
      "From State FrogState(position=5):\n",
      "  With Action A:\n",
      "    To [State FrogState(position=4) and Reward 0.000] with Probability 0.500\n",
      "    To [State FrogState(position=6) and Reward 0.000] with Probability 0.500\n",
      "  With Action B:\n",
      "    To [State FrogState(position=0) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=1) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=2) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=3) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=4) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=6) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=7) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=8) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=9) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=10) and Reward 1.000] with Probability 0.100\n",
      "From State FrogState(position=6):\n",
      "  With Action A:\n",
      "    To [State FrogState(position=5) and Reward 0.000] with Probability 0.600\n",
      "    To [State FrogState(position=7) and Reward 0.000] with Probability 0.400\n",
      "  With Action B:\n",
      "    To [State FrogState(position=0) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=1) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=2) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=3) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=4) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=5) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=7) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=8) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=9) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=10) and Reward 1.000] with Probability 0.100\n",
      "From State FrogState(position=7):\n",
      "  With Action A:\n",
      "    To [State FrogState(position=6) and Reward 0.000] with Probability 0.700\n",
      "    To [State FrogState(position=8) and Reward 0.000] with Probability 0.300\n",
      "  With Action B:\n",
      "    To [State FrogState(position=0) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=1) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=2) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=3) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=4) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=5) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=6) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=8) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=9) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=10) and Reward 1.000] with Probability 0.100\n",
      "From State FrogState(position=8):\n",
      "  With Action A:\n",
      "    To [State FrogState(position=7) and Reward 0.000] with Probability 0.800\n",
      "    To [State FrogState(position=9) and Reward 0.000] with Probability 0.200\n",
      "  With Action B:\n",
      "    To [State FrogState(position=0) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=1) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=2) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=3) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=4) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=5) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=6) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=7) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=9) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=10) and Reward 1.000] with Probability 0.100\n",
      "From State FrogState(position=9):\n",
      "  With Action A:\n",
      "    To [State FrogState(position=8) and Reward 0.000] with Probability 0.900\n",
      "    To [State FrogState(position=10) and Reward 1.000] with Probability 0.100\n",
      "  With Action B:\n",
      "    To [State FrogState(position=0) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=1) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=2) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=3) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=4) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=5) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=6) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=7) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=8) and Reward 0.000] with Probability 0.100\n",
      "    To [State FrogState(position=10) and Reward 1.000] with Probability 0.100\n",
      "FrogState(position=10) is a Terminal State\n",
      "FrogState(position=0) is a Terminal State\n",
      "\n",
      "Optimal Value Function and Optimal Policy\n",
      "-----------------------------------------\n",
      "{FrogState(position=1): 0.2824061058293976, FrogState(position=2): 0.2824061058293976, FrogState(position=3): 0.2824061058293976, FrogState(position=4): 0.2824061058293976, FrogState(position=5): 0.2824061058293976, FrogState(position=6): 0.2824061058293976, FrogState(position=7): 0.2824061058293976, FrogState(position=8): 0.2824061058293976, FrogState(position=9): 0.30332433866457054}\n",
      "For State FrogState(position=1):\n",
      "  Do Action B with Probability 1.000\n",
      "For State FrogState(position=2):\n",
      "  Do Action B with Probability 1.000\n",
      "For State FrogState(position=3):\n",
      "  Do Action B with Probability 1.000\n",
      "For State FrogState(position=4):\n",
      "  Do Action B with Probability 1.000\n",
      "For State FrogState(position=5):\n",
      "  Do Action B with Probability 1.000\n",
      "For State FrogState(position=6):\n",
      "  Do Action B with Probability 1.000\n",
      "For State FrogState(position=7):\n",
      "  Do Action B with Probability 1.000\n",
      "For State FrogState(position=8):\n",
      "  Do Action B with Probability 1.000\n",
      "For State FrogState(position=9):\n",
      "  Do Action A with Probability 1.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    gamma = 0.8\n",
    "    pad = 10\n",
    "    \n",
    "    si_mdp: FiniteMarkovDecisionProcess[FrogState, int] =\\\n",
    "        FrogMDP(\n",
    "            num_pad = pad\n",
    "        )\n",
    "\n",
    "    print(\"MDP Transition Map\")\n",
    "    print(\"------------------\")\n",
    "    print(si_mdp)\n",
    "\n",
    "    policies = list(itertools.product([0, 1], repeat = pad - 1)) \n",
    "    #print(policies)\n",
    "\n",
    "    # For each deterministic policy\n",
    "    for policy in policies:\n",
    "        # print(\"A Deterministic Policy:\")\n",
    "        fdp: FinitePolicy[FrogState, int] =\\\n",
    "            FinitePolicy(\n",
    "                {FrogState(padnum):\n",
    "                    Constant(policy[padnum - 1]) for padnum in range(1, pad)}\n",
    "            )\n",
    "        # commented out to avoid long output; uncomment the line below as needed\n",
    "        # print(fdp) \n",
    "\n",
    "\n",
    "    print(\"Optimal Value Function and Optimal Policy\")\n",
    "    print(\"-----------------------------------------\")\n",
    "    \n",
    "    opt_vf_vi, opt_policy_vi = value_iteration_result(si_mdp, gamma=gamma)\n",
    "    print(opt_vf_vi)\n",
    "    print(opt_policy_vi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
